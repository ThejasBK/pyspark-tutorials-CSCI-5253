{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Tutorial - Joins\n",
    "<div>\n",
    " <h2> CSCI 4253 / 5253 \n",
    "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"pyspark tutorial\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Value Data, Grouping and Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Key-Value or (k,v) datatype is fundemental to many operations including grouping and joins. We need to be able to:\n",
    "* Create keys from non-KV data\n",
    "* Group or organize data according to keys\n",
    "* Operate on data according to keys\n",
    "* Form standard joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Key-Pair Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly create K-V pairs using lists of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = sc.parallelize([ (\"index.html\", \"1.2.3.4\"),\n",
    "                         (\"about.html\", \"3.4.5.6\"),\n",
    "                         (\"index.html\", \"1.3.3.1\") ])\n",
    "pageNames = sc.parallelize([ (\"index.html\", \"Home\"),\n",
    "                            (\"about.html\", \"About\") ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we `collect()` the K-V pairs, we'll get the full list of keys -- this pulls the data to the front-end machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('index.html', '1.2.3.4'),\n",
       " ('about.html', '3.4.5.6'),\n",
       " ('index.html', '1.3.3.1')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first position of the K-V pair is the key. We'll cover grouping in more detail later, but let's take a look at grouping visits by the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('about.html', <pyspark.resultiterable.ResultIterable at 0x7f1939b0c4f0>),\n",
       " ('index.html', <pyspark.resultiterable.ResultIterable at 0x7f1939ac64c0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KV pairs have now been *grouped* meaning that we have an RDD of all the keys and the values for each key are a \"list\" of of the values corresponding to that key in the original KV RDD. Because the values are scattered across your cluster, a `ResultIterable` is used to represented their distributed type.\n",
    "\n",
    "We reify the results by converting it to a list. You wouldn't do this in practice because this brings all the values back to the front-end machine across the whole networking, but lets see what this produces to understand what `groupByKey` is doing.\n",
    "\n",
    "We'll `map` a lambda function that simply \"flattens\" the items by converting the `ResultIterable` into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('about.html', ['3.4.5.6']), ('index.html', ['1.2.3.4', '1.3.3.1'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits.groupByKey().map(lambda x: (x[0], list(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we `map` across a grouped KV the mapped function takes an argument which is the pair \"(key, value\") -- that's why we're referring to `x[0]` for the value and `x[1]` for the value in the sample `map`.\n",
    "\n",
    "It's more typicaly that you want to just `map` across the values and there is a corresponding `mapValues` function that does precisely this. In the example below, we are mapping `list` across the values in the groups. The results should be the same as the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('about.html', ['3.4.5.6']), ('index.html', ['1.2.3.4', '1.3.3.1'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits.groupByKey().mapValues(list).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keyBy` is a function to efficiently create a key-value pair from an RDD. The elements of the original RDD are the \"values\" and a function provides the associated key.\n",
    "\n",
    "For example, assume we want $K = V^2$ for values $V$ in an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sc.parallelize( [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3] )\n",
    "r.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (4, 2),\n",
       " (9, 3),\n",
       " (16, 4),\n",
       " (25, 5),\n",
       " (36, 6),\n",
       " (49, 7),\n",
       " (64, 8),\n",
       " (81, 9),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (4, 2),\n",
       " (9, 3)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsq = r.keyBy(lambda x : x*x)\n",
    "rsq.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we might want to create keys for the **passwd** data using the shell name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwd = sc.textFile(\"/etc/passwd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The password is the 7th field (6th index)  in the `/etc/passwd` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['root', 'x', '0', '0', 'root', '/root', '/bin/bash']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passwd.take(1)[0].split(':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, if we want the `key` to be the 6th element, we provide a function that extracts that from each entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', 'root:x:0:0:root:/root:/bin/bash'),\n",
       " ('/usr/sbin/nologin', 'daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin'),\n",
       " ('/usr/sbin/nologin', 'bin:x:2:2:bin:/bin:/usr/sbin/nologin')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell = passwd.keyBy( lambda x : x.split(':')[6] )\n",
    "byShell.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more or less equivilent to a `map` that returns pairs of values. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', 'root:x:0:0:root:/root:/bin/bash'),\n",
       " ('/usr/sbin/nologin', 'daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin'),\n",
       " ('/usr/sbin/nologin', 'bin:x:2:2:bin:/bin:/usr/sbin/nologin')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passwd.map( lambda x : (x.split(':')[6], x) ).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Key-Value Pairs\n",
    "\n",
    "We can return a dictionary containing the number of logins using each shell using the `countByKey` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'/bin/bash': 2, '/usr/sbin/nologin': 21, '/bin/sync': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can extract keys and values in parallel across the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bin/bash', '/usr/sbin/nologin', '/usr/sbin/nologin']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shellKeys = byShell.keys()\n",
    "shellKeys.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['root:x:0:0:root:/root:/bin/bash',\n",
       " 'daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin',\n",
       " 'bin:x:2:2:bin:/bin:/usr/sbin/nologin']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell.values().take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have (k,v) pairs, you can group the key -- the values are iterable ( distributed lists) of the values for that key. Earlier, we shows that you can `map` a function over the `ResultIterable` -- it's unlikely you want want to return them to a native `list` because that will pull all the values back to the front end machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', <pyspark.resultiterable.ResultIterable at 0x7f1939a63b20>),\n",
       " ('/usr/sbin/nologin',\n",
       "  <pyspark.resultiterable.ResultIterable at 0x7f1939a635b0>),\n",
       " ('/bin/sync', <pyspark.resultiterable.ResultIterable at 0x7f1939a638e0>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell.groupByKey().take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group KV pairs by other attributes using the groupBy() method. For example, here we're going to group the password data by the user name (the 0'th field of the values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', 'root:x:0:0:root:/root:/bin/bash'),\n",
       " ('/usr/sbin/nologin', 'daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin'),\n",
       " ('/usr/sbin/nologin', 'bin:x:2:2:bin:/bin:/usr/sbin/nologin')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getLogin(x):\n",
    "    return x.split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('root', <pyspark.resultiterable.ResultIterable at 0x7f1939a63d90>),\n",
       " ('daemon', <pyspark.resultiterable.ResultIterable at 0x7f1939a63610>),\n",
       " ('sync', <pyspark.resultiterable.ResultIterable at 0x7f1939a63f10>)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell.groupBy (lambda x : getLogin(x[1]) ).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once items are grouped, you can iterate over the values associated with a key.\n",
    "\n",
    "Let's group the `/etc/passwd` entries by the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', <pyspark.resultiterable.ResultIterable at 0x7f1939a7c310>),\n",
       " ('/usr/sbin/nologin',\n",
       "  <pyspark.resultiterable.ResultIterable at 0x7f1939a7c370>),\n",
       " ('/bin/sync', <pyspark.resultiterable.ResultIterable at 0x7f1939a7c340>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpdShell = byShell.groupByKey()\n",
    "grpdShell.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the key are differ Unix shells (*e.g.* `/bin/bash`) and the values are `ResultIterable`s of the values having that key in the original KV list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we typically wouldn't want to pull in all the value using a `list` because this will bring everything to the front-end machine in the cluster. But, let's convert the `ResultIterable` to a list just to see the structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash',\n",
       "  ['root:x:0:0:root:/root:/bin/bash',\n",
       "   'jovyan:x:1000:100::/home/jovyan:/bin/bash']),\n",
       " ('/usr/sbin/nologin',\n",
       "  ['daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin',\n",
       "   'bin:x:2:2:bin:/bin:/usr/sbin/nologin',\n",
       "   'sys:x:3:3:sys:/dev:/usr/sbin/nologin',\n",
       "   'games:x:5:60:games:/usr/games:/usr/sbin/nologin',\n",
       "   'man:x:6:12:man:/var/cache/man:/usr/sbin/nologin',\n",
       "   'lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin',\n",
       "   'mail:x:8:8:mail:/var/mail:/usr/sbin/nologin',\n",
       "   'news:x:9:9:news:/var/spool/news:/usr/sbin/nologin',\n",
       "   'uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin',\n",
       "   'proxy:x:13:13:proxy:/bin:/usr/sbin/nologin',\n",
       "   'www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin',\n",
       "   'backup:x:34:34:backup:/var/backups:/usr/sbin/nologin',\n",
       "   'list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin',\n",
       "   'irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin',\n",
       "   'gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin',\n",
       "   'nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin',\n",
       "   '_apt:x:100:65534::/nonexistent:/usr/sbin/nologin',\n",
       "   'systemd-timesync:x:101:101:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin',\n",
       "   'systemd-network:x:102:103:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin',\n",
       "   'systemd-resolve:x:103:104:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin',\n",
       "   'messagebus:x:104:106::/nonexistent:/usr/sbin/nologin']),\n",
       " ('/bin/sync', ['sync:x:4:65534:sync:/bin:/bin/sync'])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpdShell.map(lambda x: (x[0], list(x[1])) ).take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The better way to process this would be to would `map` a function over each KV pair in the grouped list. The key is `x[0]` and the `ResultIterable` is `x[1]`. We can then map a function over each of the  `ResultIterable` to extract some field, such as the login information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash',\n",
       "  ['root:x:0:0:root:/root:/bin/bash',\n",
       "   'jovyan:x:1000:100::/home/jovyan:/bin/bash']),\n",
       " ('/usr/sbin/nologin',\n",
       "  ['daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin',\n",
       "   'bin:x:2:2:bin:/bin:/usr/sbin/nologin',\n",
       "   'sys:x:3:3:sys:/dev:/usr/sbin/nologin',\n",
       "   'games:x:5:60:games:/usr/games:/usr/sbin/nologin',\n",
       "   'man:x:6:12:man:/var/cache/man:/usr/sbin/nologin',\n",
       "   'lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin',\n",
       "   'mail:x:8:8:mail:/var/mail:/usr/sbin/nologin',\n",
       "   'news:x:9:9:news:/var/spool/news:/usr/sbin/nologin',\n",
       "   'uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin',\n",
       "   'proxy:x:13:13:proxy:/bin:/usr/sbin/nologin',\n",
       "   'www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin',\n",
       "   'backup:x:34:34:backup:/var/backups:/usr/sbin/nologin',\n",
       "   'list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin',\n",
       "   'irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin',\n",
       "   'gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin',\n",
       "   'nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin',\n",
       "   '_apt:x:100:65534::/nonexistent:/usr/sbin/nologin',\n",
       "   'systemd-timesync:x:101:101:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin',\n",
       "   'systemd-network:x:102:103:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin',\n",
       "   'systemd-resolve:x:103:104:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin',\n",
       "   'messagebus:x:104:106::/nonexistent:/usr/sbin/nologin']),\n",
       " ('/bin/sync', ['sync:x:4:65534:sync:/bin:/bin/sync'])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grpdShell.mapValues(list).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shellAndLogins = grpdShell.map( \n",
    "    lambda x: (x[0], \",\".join( [ getLogin(y) for y in x[1] ]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', 'root,jovyan'),\n",
       " ('/usr/sbin/nologin',\n",
       "  'daemon,bin,sys,games,man,lp,mail,news,uucp,proxy,www-data,backup,list,irc,gnats,nobody,_apt,systemd-timesync,systemd-network,systemd-resolve,messagebus'),\n",
       " ('/bin/sync', 'sync')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shellAndLogins.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than first group the keys and then combine the values into the string above, we can use **foldByKey** to do more or less the same thing -- this combines the mapping phase implicit in the list comprehension above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', 'root,jovyan,,'),\n",
       " ('/usr/sbin/nologin',\n",
       "  'daemon,bin,sys,games,man,lp,mail,news,uucp,proxy,www-data,backup,list,irc,gnats,nobody,_apt,systemd-timesync,systemd-network,systemd-resolve,messagebus,,'),\n",
       " ('/bin/sync', 'sync,')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell.foldByKey( \"\", lambda x,y: x + getLogin(y) + ',' ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, this is done using a \"combiner(createCombiner, mergeValue, mergeCombiners)\", which turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a \"combined type\" C.  Note that V and C can be different -- for example, one might group an RDD of type (Int, Int) into an RDD of type (Int, List[Int]).\n",
    "\n",
    "This example takes the byShell (K,V) list and constructs a new V there is the name of the users of that shell. Entries within the same RDD partition are joined by a comma and between partitions by \"AND\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/bin/bash', 'root AND jovyan'),\n",
       " ('/usr/sbin/nologin',\n",
       "  'daemon,bin,sys,games,man,lp,mail,news,uucp,proxy,www-data,backup,list AND irc,gnats,nobody,_apt,systemd-timesync,systemd-network,systemd-resolve,messagebus'),\n",
       " ('/bin/sync', 'sync')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "byShell.combineByKey( getLogin,\n",
    "                        lambda xs, x: xs + ',' + getLogin(x),\n",
    "                        lambda xs, ys: xs + ' AND ' + ys ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**combineByKey** is used to develop \"reduceByKey\" functions that can e.g. sum up the items associated with a key. This is effectively doing a **groupByKey** followed by a **reduce** on each list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "c = sc.parallelize([ (1,2), (2,3), (1, 99), (3, 44), (2, 1), (4,5), (3, 19) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupByKey` operator gives us `iterable` items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, <pyspark.resultiterable.ResultIterable at 0x7f1939a8bf10>),\n",
       " (4, <pyspark.resultiterable.ResultIterable at 0x7f1939b0cd00>),\n",
       " (1, <pyspark.resultiterable.ResultIterable at 0x7f1939b0cc40>),\n",
       " (3, <pyspark.resultiterable.ResultIterable at 0x7f1939b0c910>)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reify (make concrete) the iterable item by convert it to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, [3, 1]), (4, [5]), (1, [2, 99]), (3, [44, 19])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.groupByKey().map(lambda x : (x[0], list(x[1]))).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reduceByKey` groups identical keys and then applys a function over the iterable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 4), (4, 5), (1, 101), (3, 63)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.reduceByKey( operator.add ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoGroup - the basis for joins\n",
    "\n",
    "As in Pig, joins are done performing \"co-groups\" where multiple data sets are grouped by the same key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (1, 99), (3, 44), (2, 1), (4, 5), (3, 19)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = c\n",
    "s1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, -99), (4, 199), (19, 23)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = sc.parallelize( [ (2, -99), ( 4, 199), (19, 23) ] )\n",
    "s2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939ac6520>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a7c4c0>)),\n",
       " (1,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939a7cee0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a7cf70>)),\n",
       " (2,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939a7cfa0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a7ca00>)),\n",
       " (3,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939a7c8b0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a7c8e0>)),\n",
       " (19,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939a7cb80>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a7cdc0>))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co = s1.cogroup(s2)\n",
    "co.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our \"convert it to a list trick\" to see what's in each cogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, [5], [199]),\n",
       " (1, [2, 99], []),\n",
       " (2, [3, 1], [-99]),\n",
       " (3, [44, 19], []),\n",
       " (19, [], [23])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co.map(lambda x: (x[0], list(x[1][0]), list(x[1][1])) ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to build different kinds of joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, (5, 199)), (2, (3, -99)), (2, (1, -99))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.join(s2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, (5, 199)),\n",
       " (1, (2, None)),\n",
       " (1, (99, None)),\n",
       " (2, (3, -99)),\n",
       " (2, (1, -99)),\n",
       " (3, (44, None)),\n",
       " (3, (19, None))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.leftOuterJoin(s2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, (5, 199)), (2, (3, -99)), (2, (1, -99)), (19, (None, 23))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.rightOuterJoin(s2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = sc.parallelize( [ (\"NY\", 10), (\"OH\", 20), (\"OH\", 99), (\"CO\", 88) ] )\n",
    "y = sc.parallelize( [ (\"NY\", 30), (\"CO\", 40), (\"NY\", 22 )] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', (10, 30)), ('NY', (10, 22)), ('CO', (88, 40))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.join(y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', 10), ('NY', 30), ('NY', 10), ('NY', 22), ('CO', 88), ('CO', 40)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.join(y).flatMap(lambda kv: ((kv[0],x) for x in kv[1])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OH',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939a23970>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a23d00>)),\n",
       " ('NY',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939a23f70>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a23670>)),\n",
       " ('CO',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f1939a23790>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f1939a23550>))]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cogroup(y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NY', 10, 30), ('NY', 10, 22), ('CO', 88, 40)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.cogroup(y).flatMap(lambda kv: ((kv[0],x,y) for x in kv[1][0] for y in kv[1][1])).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
